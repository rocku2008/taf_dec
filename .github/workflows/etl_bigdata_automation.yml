name: ETL Automation

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install pyspark azure-storage-blob pyodbc

    - name: Download JARs
      run: |
        mkdir -p ./jars
        wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/3.3.1/hadoop-azure-3.3.1.jar -P ./jars
        wget https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/8.6.6/azure-storage-8.6.6.jar -P ./jars
        wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure-datalake/3.3.1/hadoop-azure-datalake-3.3.1.jar -P ./jars
        wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar -P ./jars

    - name: Set Spark Configuration
      run: |
        echo "SPARK_JARS=$(pwd)/jars/postgresql-42.2.5.jar,$(pwd)/jars/snowflake-jdbc-3.22.0.jar,$(pwd)/jars/azure-storage-8.6.6.jar,$(pwd)/jars/hadoop-azure-3.3.1.jar,$(pwd)/jars/mssql-jdbc-12.2.0.jre8.jar" >> $GITHUB_ENV

    - name: Test with pytest
      run: |
        export PYSPARK_SUBMIT_ARGS="--jars $SPARK_JARS --driver-class-path $SPARK_JARS --conf spark.driver.extraClassPath=$SPARK_JARS --conf spark.executor.extraClassPath=$SPARK_JARS pyspark-shell"
        python runner.py

