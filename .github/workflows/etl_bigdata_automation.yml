name: ETL Big Data Automation

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Download and Install Apache Spark
      run: |
        # Set variables for Spark version and Hadoop version
        SPARK_VERSION=3.3.0
        HADOOP_VERSION=hadoop3.2
        DOWNLOAD_URL=https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz
        TARGET_DIR=/opt/spark

        # Download Apache Spark
        wget ${DOWNLOAD_URL} -O /tmp/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz

        # Verify if the download was successful
        if [ $? -ne 0 ]; then
          echo "Download failed! Please check the URL."
          exit 1
        fi

        # Extract Spark to the target directory
        tar -xvzf /tmp/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz -C /opt/

        # Set environment variables for Spark
        echo "export SPARK_HOME=/opt/spark/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}" >> $GITHUB_ENV
        echo "export PATH=$SPARK_HOME/bin:$PATH" >> $GITHUB_ENV

    - name: Download necessary JARs
      run: |
        # Create a directory to store JARs
        mkdir -p $SPARK_HOME/jars

        # Download all necessary JARs
        wget https://repo1.maven.org/maven2/net/snowflake/snowflake-jdbc/3.22.0/snowflake-jdbc-3.22.0.jar -P $SPARK_HOME/jars/
        wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar -P $SPARK_HOME/jars/
        wget https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/8.6.6/azure-storage-8.6.6.jar -P $SPARK_HOME/jars/
        wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/3.3.1/hadoop-azure-3.3.1.jar -P $SPARK_HOME/jars/
        wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.2.0.jre8/mssql-jdbc-12.2.0.jre8.jar -P $SPARK_HOME/jars/

    - name: Set Spark configurations for JARs
      run: |
        # Configure Spark to use the downloaded JARs
        echo "export SPARK_CONF_DIR=$SPARK_HOME/conf" >> $GITHUB_ENV
        echo "spark.jars=$(find $SPARK_HOME/jars -type f | tr '\n' ',')" >> $GITHUB_ENV

    - name: Automation execution
      run: |
        python runner.py
