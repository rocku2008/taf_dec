name: ETL Big Data Automation

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Install Spark with JAR dependencies
      run: |
        SPARK_VERSION=3.3.0
        HADOOP_VERSION=hadoop3.2
        DOWNLOAD_URL=https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz
        TARGET_DIR=/opt/spark

        # Download Apache Spark
        wget ${DOWNLOAD_URL} -O /tmp/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz

        # Verify if the download was successful
        if [ $? -ne 0 ]; then
          echo "Download failed! Please check the URL."
          exit 1
        fi

        # Extract Spark to the target directory
        tar -xvzf /tmp/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}.tgz -C /opt/

        # Set environment variables for Spark
        echo "export SPARK_HOME=/opt/spark/spark-${SPARK_VERSION}-bin-${HADOOP_VERSION}" >> $GITHUB_ENV
        echo "export PATH=$SPARK_HOME/bin:$PATH" >> $GITHUB_ENV

        # Create directories for JARs
        mkdir -p $SPARK_HOME/jars

        # Download required JARs in parallel using background processes
        wget https://repo1.maven.org/maven2/net/snowflake/snowflake-jdbc/3.22.0/snowflake-jdbc-3.22.0.jar -P $SPARK_HOME/jars/ &
        wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar -P $SPARK_HOME/jars/ &
        wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.2.0.jre8/mssql-jdbc-12.2.0.jre8.jar -P $SPARK_HOME/jars/ &
        wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/3.3.1/hadoop-azure-3.3.1.jar -P $SPARK_HOME/jars/ &
        wget https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/8.6.6/azure-storage-8.6.6.jar -P $SPARK_HOME/jars/ &

        # Wait for all downloads to complete
        wait

        # Set Spark JARs configuration to include the downloaded JARs
        echo "spark.jars=$SPARK_HOME/jars/snowflake-jdbc-3.22.0.jar,$SPARK_HOME/jars/postgresql-42.2.5.jar,$SPARK_HOME/jars/mssql-jdbc-12.2.0.jre8.jar,$SPARK_HOME/jars/hadoop-azure-3.3.1.jar,$SPARK_HOME/jars/azure-storage-8.6.6.jar" >> $GITHUB_ENV

    - name: Run automation execution
      run: |
        python runner.py

    - name: Run tests
      run: |
        pytest tests/
